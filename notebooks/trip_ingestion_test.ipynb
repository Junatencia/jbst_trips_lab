{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cab3e7ba",
   "metadata": {},
   "source": [
    "# Trip Ingestion Project - Testing Mandatory Features\n",
    "This notebook documents and tests all **mandatory features** of the data ingestion project.\n",
    "Each section corresponds to one feature requirement from the assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d81ba637",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trip_ingestion_test.ipynb\n",
    "\n",
    "# ---\n",
    "# # Trip Ingestion Project — Test Notebook\n",
    "# This notebook documents and tests all mandatory features of the project:\n",
    "# 1. Upload CSV to FastAPI\n",
    "# 2. Track ingestion job status (via WebSocket)\n",
    "# 3. Validate data stored in Postgres\n",
    "# 4. Run analytics queries (grouping + weekly averages)\n",
    "# 5. Show scalability proof of concept\n",
    "# ---\n",
    "\n",
    "import os\n",
    "import csv\n",
    "import requests\n",
    "import websockets\n",
    "import asyncio\n",
    "import json\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "BASE_URL = \"http://localhost:8000\"   # FastAPI service\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "DB_HOST = os.getenv(\"DB_HOST\", \"localhost\")\n",
    "DB_PORT = os.getenv(\"DB_PORT\", \"5432\")\n",
    "DB_NAME = os.getenv(\"DB_NAME\", \"tripsdb\")\n",
    "DB_USER = os.getenv(\"DB_USER\", \"postgres\")\n",
    "DB_PASS = os.getenv(\"DB_PASS\", \"postgres\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecbc68ff",
   "metadata": {},
   "source": [
    "## 1. Health check API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc6e7a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "r = requests.get(f\"{BASE_URL}/health\")\n",
    "print(r.json())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "334fd380",
   "metadata": {},
   "source": [
    "## 2. Automated Process to Ingest and Store the Data\n",
    "**Goal:** Upload a CSV file via API and store it in Postgres.\n",
    "\n",
    "\n",
    "**Test:** Send a request to the API and check that rows appear in the `trips` table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa694b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "url = \"http://localhost:8000/ingest\"  # your API URL\n",
    "file_path = \"../source_data/trips.csv\"\n",
    "\n",
    "with open(file_path, \"rb\") as f:\n",
    "    response = requests.post(url, files={\"file\": f})\n",
    "\n",
    "print(response.status_code)\n",
    "print(response.json())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95d1df99",
   "metadata": {},
   "source": [
    "Expected output:\n",
    "\n",
    "{'job_id': \"uuid-string\",\n",
    " 'status': 'running',\n",
    " 'message': 'Started ingestion: trips.csv'}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c239249",
   "metadata": {},
   "source": [
    "## 3. Track ingestion status via WebSocket // Inform User About Status of Ingestion Without Polling\n",
    "**Goal:** Use WebSockets to receive job status in real-time.\n",
    "\n",
    "\n",
    "**Test:** Connect to `/ws/{job_id}` endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcb1d368",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def track_status(job_id):\n",
    "    uri = f\"ws://localhost:8000/ws/{job_id}\"\n",
    "    async with websockets.connect(uri) as ws:\n",
    "        while True:\n",
    "            msg = await ws.recv()\n",
    "            data = json.loads(msg)\n",
    "            print(data)\n",
    "            if data[\"status\"].startswith(\"completed\") or data[\"status\"].startswith(\"failed\"):\n",
    "                break\n",
    "\n",
    "job_id = resp.json()[\"job_id\"]\n",
    "print(f\"Tracking status for job_id: {job_id}\")\n",
    "await track_status(job_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "317df0d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geohash2\n",
    "print(geohash2.encode(4.6, -74.1, precision=5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15e6b58d",
   "metadata": {},
   "source": [
    "## 4. Validate stored data in Postgres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2bc4cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Check DB row count (using SQLAlchemy)\n",
    "from sqlalchemy import create_engine, text\n",
    "\n",
    "engine = create_engine(\"postgresql://postgres:postgres@localhost:5432/tripsdb\")\n",
    "with engine.connect() as conn:\n",
    "    result = conn.execute(text(\"SELECT count(*) FROM trips;\"))\n",
    "    print(\"Trips loaded:\", result.scalar())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b972cf4",
   "metadata": {},
   "source": [
    "## 2. Analytics — Grouping trips by city // Group Trips with Similar Origin, Destination, and Time of Day\n",
    "**Goal:** Trips are grouped by geohash of origin/destination and time bucket.\n",
    "\n",
    "**Test:** Run a query grouping trips and confirm grouping works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9f3e3e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check DB row count (using SQLAlchemy)\n",
    "from sqlalchemy import create_engine, text\n",
    "sql = \"\"\"\n",
    "SELECT region, COUNT(*) AS trip_count\n",
    "FROM trips\n",
    "GROUP BY region\n",
    "ORDER BY trip_count DESC;\n",
    "\"\"\"\n",
    "\n",
    "engine = create_engine(\"postgresql://postgres:postgres@localhost:5432/tripsdb\")\n",
    "with engine.connect() as conn:\n",
    "    df = pd.read_sql(sql, conn)\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f70f0db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = '''\n",
    "SELECT origin_geohash, dest_geohash, tod_bucket, COUNT(*) AS trips\n",
    "FROM trip_groups\n",
    "GROUP BY 1,2,3\n",
    "ORDER BY trips DESC\n",
    "LIMIT 10;\n",
    "'''\n",
    "with engine.connect() as conn:\n",
    "    print(conn.execute(text(query)).fetchall())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af4489fc",
   "metadata": {},
   "source": [
    "## 6. Analytics — Weekly averages inside bounding box // Weekly Average Number of Trips for an Area\n",
    "**Goal:** Calculate weekly averages within a bounding box.\n",
    "\n",
    "**Test:** Use PostGIS query with bounding box filter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ca2abe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = '''\n",
    "WITH weekly AS (\n",
    "  SELECT date_trunc('week', trip_ts) wk, count(*) c\n",
    "  FROM trips\n",
    "  WHERE ST_Within(origin, ST_MakeEnvelope(-74.2,4.5,-74.0,4.8,4326))\n",
    "  GROUP BY 1\n",
    ")\n",
    "SELECT avg(c) AS weekly_avg FROM weekly;\n",
    "'''\n",
    "with engine.connect() as conn:\n",
    "    print(conn.execute(text(query)).fetchall())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff9dbd01",
   "metadata": {},
   "source": [
    "## 4. Inform User About Status of Ingestion Without Polling\n",
    "**Goal:** Use WebSockets to receive job status in real-time.\n",
    "\n",
    "\n",
    "**Test:** Connect to `/ws/{job_id}` endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e110f8ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import websockets, asyncio, json\n",
    "\n",
    "async def test_ws(job_id):\n",
    "    uri = f\"ws://localhost:8000/ws/{job_id}\"\n",
    "    async with websockets.connect(uri) as websocket:\n",
    "        for _ in range(5):\n",
    "            msg = await websocket.recv()\n",
    "            print(\"Received:\", json.loads(msg))\n",
    "\n",
    "# Replace with a valid job_id returned from ingestion\n",
    "#job_id = \"REPLACE_WITH_JOB_ID\"\n",
    "#job_id = resp.json()[\"job_id\"]\n",
    "asyncio.run(test_ws(job_id))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38edddf8",
   "metadata": {},
   "source": [
    "## 5. Scalability Proof to 100M Entries\n",
    "**Goal:** Demonstrate ingestion and query performance at scale.\n",
    "\n",
    "\n",
    "**Test:** Generate synthetic trips and bulk load them into Postgres, then measure throughput."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bcd5bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Generate 1 million synthetic rows (small test, extrapolate to 100M)\n",
    "n = 10**6\n",
    "base_time = datetime(2025,1,1)\n",
    "data = {\n",
    "    \"trip_ts\": [base_time + timedelta(seconds=i*60) for i in range(n)],\n",
    "    \"city\": [\"testcity\"]*n,\n",
    "    \"origin_lat\": np.random.uniform(4.5, 4.8, n),\n",
    "    \"origin_lon\": np.random.uniform(-74.2, -74.0, n),\n",
    "    \"dest_lat\": np.random.uniform(4.5, 4.8, n),\n",
    "    \"dest_lon\": np.random.uniform(-74.2, -74.0, n),\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "df.to_csv(\"synthetic_trips.csv\", index=False)\n",
    "print(\"Synthetic CSV generated with\", len(df), \"rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dd87bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\"region\": \"Prague\"}\n",
    "response = requests.get(f\"{BASE_URL}/trips/weekly_average/\", params=params)\n",
    "print(response.json())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d8dc808",
   "metadata": {},
   "source": [
    "Next step: Use Postgres `COPY` command or SQLAlchemy bulk insert to load this file.\n",
    "Then run `EXPLAIN ANALYZE` queries to measure performance and document results here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ceab436",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
